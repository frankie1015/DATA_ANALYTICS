{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "soybean = fetch_ucirepo(id=91) \n",
    "zoo = fetch_ucirepo(id=111)\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "dermatology = fetch_ucirepo(id=33)\n",
    "breast_cancer = fetch_ucirepo(id=15)\n",
    "mushroom = fetch_ucirepo(id=73)\n",
    "\n",
    "# Convert datasets to DataFrames\n",
    "# Replace 'features' and 'targets' with the actual attribute names\n",
    "soybean_df = pd.DataFrame(data=soybean.data.features, columns=soybean.data.feature_names)\n",
    "soybean_df['target'] = soybean.data.targets\n",
    "\n",
    "zoo_df = pd.DataFrame(data=zoo.data.features, columns=zoo.data.feature_names)\n",
    "zoo_df['target'] = zoo.data.targets\n",
    "\n",
    "heart_disease_df = pd.DataFrame(data=heart_disease.data.features, columns=heart_disease.data.feature_names)\n",
    "heart_disease_df['target'] = heart_disease.data.targets\n",
    "\n",
    "dermatology_df = pd.DataFrame(data=dermatology.data.features, columns=dermatology.data.feature_names)\n",
    "dermatology_df['target'] = dermatology.data.targets\n",
    "\n",
    "breast_cancer_df = pd.DataFrame(data=breast_cancer.data.features, columns=breast_cancer.data.feature_names)\n",
    "breast_cancer_df['target'] = breast_cancer.data.targets\n",
    "\n",
    "mushroom_df = pd.DataFrame(data=mushroom.data.features, columns=mushroom.data.feature_names)\n",
    "mushroom_df['target'] = mushroom.data.targets\n",
    "\n",
    "# Ensure the datasets are properly defined before proceeding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def jaccard_coefficient(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union\n",
    "\n",
    "def ochiai_coefficient(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    denominator = np.sqrt(len(set1) * len(set2))\n",
    "    return intersection / denominator\n",
    "\n",
    "def overlap_coefficient(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    min_length = min(len(set1), len(set2))\n",
    "    return intersection / min_length\n",
    "\n",
    "def dice_coefficient(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    denominator = len(set1) + len(set2)\n",
    "    return 2 * intersection / denominator\n",
    "\n",
    "def graph_based_representation(data):\n",
    "    num_samples, num_features = data.shape\n",
    "    similarity_matrix = np.zeros((num_features, num_features))\n",
    "    for i, j in itertools.combinations(range(num_features), 2):\n",
    "        similarity_matrix[i, j] = jaccard_coefficient(set(data[:, i]), set(data[:, j]))\n",
    "        similarity_matrix[j, i] = similarity_matrix[i, j]\n",
    "    G = nx.from_numpy_array(similarity_matrix)\n",
    "    embedding = SpectralEmbedding(n_components=p)\n",
    "    representation_matrix = embedding.fit_transform(similarity_matrix)\n",
    "    return representation_matrix\n",
    "\n",
    "def joint_operation(data, representation_matrix):\n",
    "    return np.dot(data, representation_matrix)\n",
    "\n",
    "def mean_operation(data, representation_matrix):\n",
    "    return np.mean(np.dot(data, representation_matrix), axis=1)\n",
    "\n",
    "def perform_clustering(data, k):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    return kmeans.fit_predict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FREDDIE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\FREDDIE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\FREDDIE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\FREDDIE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\FREDDIE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Dataset       ARI       NMI       FMI\n",
      "0        soybean_df  0.654719  0.718860  0.758713\n",
      "1            zoo_df  0.695380  0.698895  0.792488\n",
      "2  heart_disease_df  0.092516  0.125321  0.403703\n",
      "3    dermatology_df  0.291307  0.328613  0.485086\n",
      "4  breast_cancer_df  0.694342  0.563490  0.853592\n",
      "5       mushroom_df  0.270956  0.240795  0.591300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FREDDIE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Define clustering functions\n",
    "def create_graph_representation(data):\n",
    "    num_samples, num_features = data.shape\n",
    "    similarity_matrix = np.zeros((num_features, num_features))\n",
    "    for i, j in itertools.combinations(range(num_features), 2):\n",
    "        similarity_matrix[i, j] = jaccard_coefficient(set(data[:, i]), set(data[:, j]))\n",
    "        similarity_matrix[j, i] = similarity_matrix[i, j]\n",
    "    G = nx.from_numpy_array(similarity_matrix)\n",
    "    embedding = SpectralEmbedding(n_components=num_components)\n",
    "    representation_matrix = embedding.fit_transform(similarity_matrix)\n",
    "    return representation_matrix\n",
    "\n",
    "def apply_joint_operation(data, representation_matrix):\n",
    "    return np.dot(data, representation_matrix)\n",
    "\n",
    "def cluster_data(data, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    return kmeans.fit_predict(data)\n",
    "\n",
    "# Define parameters\n",
    "num_components = 10\n",
    "num_clusters = 3\n",
    "\n",
    "# Define a list to store results\n",
    "performance_results = []\n",
    "\n",
    "# Define datasets as a dictionary\n",
    "datasets = {\n",
    "    \"soybean_df\": soybean_df,\n",
    "    \"zoo_df\": zoo_df,\n",
    "    \"heart_disease_df\": heart_disease_df,\n",
    "    \"dermatology_df\": dermatology_df,\n",
    "    \"breast_cancer_df\": breast_cancer_df,\n",
    "    \"mushroom_df\": mushroom_df\n",
    "}\n",
    "\n",
    "# Loop over dataset names\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    # Suppress warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "        \n",
    "        # Data preprocessing and clustering\n",
    "        try:\n",
    "            X = dataset.drop(columns=[dataset.columns[-1]])  # Assuming the last column is the target\n",
    "            y = dataset[dataset.columns[-1]]  # Assuming the last column is the target\n",
    "            encoder = OneHotEncoder()\n",
    "            X_encoded = encoder.fit_transform(X)\n",
    "            representation_matrix = create_graph_representation(X_encoded.toarray())\n",
    "            integrated_data = apply_joint_operation(X_encoded.toarray(), representation_matrix)\n",
    "            labels = cluster_data(integrated_data, num_clusters)\n",
    "\n",
    "            ARI = adjusted_rand_score(y, labels)\n",
    "            NMI = normalized_mutual_info_score(y, labels)\n",
    "            FMI = fowlkes_mallows_score(y, labels)\n",
    "            \n",
    "            # Store results\n",
    "            performance_results.append([dataset_name, ARI, NMI, FMI])\n",
    "        except UserWarning as e:\n",
    "            print(f\"Warning: {e}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(performance_results, columns=[\"Dataset\", \"ARI\", \"NMI\", \"FMI\"])\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare and contrast each performance index, what are the advantages and disadvantages of ARI, NMI, and FMI, and when to use each?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three tools: Adjusted Rand Index, Normalized Mutual Information, and Folkes-Mallows Index, are popular ways to measure how well algorithms group things together.\n",
    "\n",
    "All three assess how well a predicted clustering matches the true labels (ground truth). They provide scores between -1 (complete disagreement) and 1 (perfect agreement). They're also useful for comparing different clustering algorithms or their settings.\n",
    "\n",
    "However, they differ in their focus and sensitivity. ARI considers how often data points are grouped together (or apart) in both predicted and true labels. It accounts for random clustering but favors solutions with more clusters. NMI focuses on the information shared between the two clusterings and is less sensitive to cluster numbers, but doesn't directly address chance agreement. FMI is similar to NMI in terms of cluster sensitivity and focuses on correctly placed data points, also not directly addressing chance agreement.\n",
    "\n",
    "Here's how to pick the best metric: Use ARI if the number of clusters varies significantly or chance agreement is a big concern. Use NMI if the number of clusters is less of an issue and you want to understand the information shared between the true and predicted clusterings. Finally, use FMI if the number of clusters is less of a concern and you want to focus on the number of correctly classified points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Kmodes and Hierarchical Clustering, use the same dataset and perform categorical data clustering, use FMI, ARI, and NMI for the comparison of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Dataset       ARI       NMI       FMI\n",
      "0              soybean_df (K-Modes)  0.653689  0.837666  0.783908\n",
      "1         soybean_df (Hierarchical)  0.653689  0.837666  0.783908\n",
      "2                  zoo_df (K-Modes)  0.727582  0.729576  0.815845\n",
      "3             zoo_df (Hierarchical)  0.461701  0.585056  0.645736\n",
      "4        heart_disease_df (K-Modes)  0.094425  0.174192  0.410031\n",
      "5   heart_disease_df (Hierarchical)  0.012003  0.013638  0.351372\n",
      "6          dermatology_df (K-Modes)  0.523548  0.651525  0.681949\n",
      "7     dermatology_df (Hierarchical)  0.031635  0.076679  0.291702\n",
      "8        breast_cancer_df (K-Modes)  0.407178  0.436138  0.684170\n",
      "9   breast_cancer_df (Hierarchical)  0.718035  0.630146  0.860889\n",
      "10            mushroom_df (K-Modes)  0.169824  0.211118  0.531541\n",
      "11       mushroom_df (Hierarchical)  0.448900  0.445047  0.711999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score\n",
    "from kmodes.kmodes import KModes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "k = 3\n",
    "def preprocess_and_encode_categorical_data(data):\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_data = data.apply(encoder.fit_transform)\n",
    "    return encoded_data\n",
    "\n",
    "def perform_clustering_and_evaluate_performance(data, true_labels, num_clusters):\n",
    "    km = KModes(n_clusters=num_clusters, init='Huang', n_init=5, verbose=0)\n",
    "    km_labels = km.fit_predict(data)\n",
    "    ARI_km = adjusted_rand_score(true_labels, km_labels)\n",
    "    NMI_km = normalized_mutual_info_score(true_labels, km_labels)\n",
    "    FMI_km = fowlkes_mallows_score(true_labels, km_labels)\n",
    "\n",
    "    ac = AgglomerativeClustering(n_clusters=num_clusters, linkage='ward')\n",
    "    ac_labels = ac.fit_predict(data)\n",
    "    ARI_ac = adjusted_rand_score(true_labels, ac_labels)\n",
    "    NMI_ac = normalized_mutual_info_score(true_labels, ac_labels)\n",
    "    FMI_ac = fowlkes_mallows_score(true_labels, ac_labels)\n",
    "    \n",
    "    return [\n",
    "        [\"K-Modes\", ARI_km, NMI_km, FMI_km],\n",
    "        [\"Hierarchical\", ARI_ac, NMI_ac, FMI_ac]\n",
    "    ]\n",
    "\n",
    "results_categorical = []\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    dataset = globals()[dataset_name]\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "        try:\n",
    "            X_cat = dataset.iloc[:, :-1]\n",
    "            true_labels_cat = dataset.iloc[:, -1]\n",
    "\n",
    "            X_cat_encoded = preprocess_and_encode_categorical_data(X_cat)\n",
    "            clustering_results = perform_clustering_and_evaluate_performance(X_cat_encoded, true_labels_cat, k)  # Pass 'k' as parameter\n",
    "\n",
    "            for method, ari, nmi, fmi in clustering_results:\n",
    "                results_categorical.append([dataset_name + \" (\" + method + \")\", ari, nmi, fmi])\n",
    "        except UserWarning as e:\n",
    "            print(f\"Warning: {e}\")\n",
    "\n",
    "results_categorical_df = pd.DataFrame(results_categorical, columns=[\"Dataset\", \"ARI\", \"NMI\", \"FMI\"])\n",
    "print(results_categorical_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your report using Latex. Your report should be focused on the \"why's and the what's\" of each performance metrices (i.e. why is FMI always greater than ARI and NMI? What's the problem with ARI and NMI?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In clustering analysis, various performance metrics are used to evaluate the quality of clustering results. Commonly used metrics include Adjusted Rand Index (ARI), Normalized Mutual Information (NMI), and Folkes-Mallows Index (FMI). In this report, we explore the characteristics and differences of these metrics, discussing their advantages and limitations.\n",
    "\n",
    "ARI measures the similarity between two clusterings by considering all pairs of samples and counting pairs that are assigned to the same or different clusters in the predicted and true clusterings. ARI produces a value between -1 and 1, where 1 indicates perfect similarity between the two clusterings.\n",
    "\n",
    "NMI measures the mutual dependence between the predicted and true clusterings, normalized to produce a value between 0 and 1. NMI is based on information theory principles and is commonly used in clustering evaluation.\n",
    "\n",
    "FMI measures the geometric mean of pairwise precision and recall, providing a single value that captures both clustering purity and homogeneity.\n",
    "\n",
    "Each performance metric has its own strengths and weaknesses, and the choice of metric depends on the specific characteristics of the dataset and the goals of the clustering analysis. ARI is suitable for evaluating clustering algorithms when the ground truth labels are available, while NMI and FMI provide alternative perspectives on clustering quality that may be more robust to certain dataset properties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
